안녕하세요 3조 발표를 맡은 김영원입니다. (인사)
팀명은 누가 기침소리를 내었조
팀장은 김영원
팀원으로 정호영, 김혜원 입니다.
음향 데이터 Covid-19 검출 AI 기반 서비스 발표를 시작하겠습니다.

목차 설명드리겠습니다.
프로젝트 개요
인공지능
챗봇
플라스크
마무리 순서로 발표하겠습니다.

(넘김)

팀 구성 및 역할입니다.
저는 머신러닝/데이터분석
정호영님은 챗봇/RPA
김혜원님은 웹 프레임워크/데이터베이스를 담당하셨습니다.

프로젝트 시작 전 코로나를 검색했을 때
4개의 이슈를 볼 수 있었는데
코로나 확진 환자가 증가하는 추세이다
자가 진단 키트 가격이 수요에 따라 증가하고 있다
자가키트가 의료 인력의 소진을 막아주지만 정확도에서 차이가 발생한다
PCR 검사에 대해 회피하는 경향을 보인다를 볼 수 있었습니다

뉴스 기사를 토대로 워드 클라우드를 진행했고
시민들이 자가진단 키트의 가격에 대해 부담감을 느낀다고 해석할 수 있었습니다.

따라서 기존의 방법보다 손쉽고 빠른 검사를 제공하는
서비스를 기획하게 되었습니다.

개발 흐름은
프로젝트 기획
데이터 확보
모델 선정 및 학습
서버 구축
발표 준비로 진행했습니다.

일정표에서는 모델 선정 및 학습을 제하고
대부분의 일정은 2~3주 내에 완료하는 것을 목표로 잡았습니다.

테스트 케이스로 각 단계별 진행상항을 기록하면서
일정을 조율했습니다.

유스케이스에서는 사용자와 관리자가 각각 어느 기능을
사용하는지 정리해 두었습니다.
부가적인 설명은 후에 나올 시연영상을 보시면서 같이 말씀드리겠습니다.

기술 스택에서는 몇개만 짚어보고 넘어가도록 하겠습니다.
데이터 수집은 RPA를 사용했습니다.
웹 프레임워크는 플라스크로 구축하고 Dialogflow로 챗봇을 추가했습니다.
개발 언어는 파이썬을 사용했습니다
AI에서는 librosa를 사용해 목소리 특징을 추출했습니다.

시연 영상 보시겠습니다.

===================================================
인공지능 파트입니다.

모델은 사용자가 기침 소리를 녹음하면
음성 파일을 주파수 단위의 이미지로 변환한 후
멜 단위의 스펙트로그램으로 변환해
모델에서 양성인지 음성인지 분류합니다.

데이터는 데이콘에서 제공하는 데이터셋을 사용했고
밑의 이미지는 각각 음성과 양성 기침소리를 테스트로 변환해 본 이미지입니다.

데이터의 전처리 과정은
원본인 음성 데이터를 멜 스펙트로그램으로 변환하고
결측치/이상치를 제거 한 뒤
마지막으로 데이터 증강을 실시했습니다.

결측치/이상치 제거는 제가 일일이 확인하면서 분류했고
음성 304개 양성 43개를 제거했습니다.
종류로는 대화하는 소리, 생활 소음, 무음, 
나이 1세에 성별이 other인 이상치 등이 있었습니다.

음향 데이터 증강으로는
잡음을 섞어 넣는 white_noise
재생 시간을 앞이나 뒤로 미는 shifting
소리를 길게 늘리는 stretching을 사용했습니다.

이제 데이터 전처리 과정은 끝났고 모델로 들어가겠습니다.
저희 프로젝트에선 전이학습을 사용했는데
간단히 설명드리자면
기존 머신러닝은 모델이 독립적으로 학습한 데이터만을 다루는 방법이라면
전이 학습은 이미 학습된 모델을 가져와서 저희의 데이터셋에 적용하는 방법입니다.

혹시 이미지넷 챌린지를 들어보셨나요?
전 세계의 연구진이 이미지 분류에 뛰어난 모델을 만들어
성능을 가리는 대회인데요.

저희 프로젝트에서는 전이학습에 이 대회에 나왔던
모델 2개인 vggnet과 resnet을 사용했습니다.

우선 resnet 실행 기록부터 말씀드리겠습니다.
처음엔 테스트로 학습이 제대로 진행되는지 확인했고
train 데이터셋을 늘려서 학습량을 높였습니다.
양성과 음성에 맡게 출력 뉴런수를 2개로 조정했습니다.
결측치와 이상치를 제거했습니다.
투명도가 필요없었기 때문에 png 파일에서 jpg 파일로 바꿨습니다.

이후 learning rate를 바꾸면서 어떤 변화가 있는지 확인했습니다.

선 그래프로 그리면 이런 형태로 나오게 되는데
뭔가 제가 생각한 그래프가 아니였습니다.
그래서 다시 코드를 천천히 살펴보면서 생각해보니
seed값을 고정하니 않은 것을 알게되었습니다.

그래서 seed값을 고정하고 다시 해야 했습니다.
여기서 부터는 학습용 데이터가 부족한것 같아서
데이터 증강으로 갯수를 늘려서 진행했습니다.
그래프를 보시면 증강하면서 데이터가 많아져서 그런지
Train에서 정확도가 오히려 내려간 것을 확인했고
1000번까지 진행해도 정확도가 오르는 경향은 없는 것을 볼 수 있습니다.

배치 사이즈를 바꾸면서 그래프를 그려봤을때
전체적으로 Test의 변동폭이 큰 것을 볼 수 있었습니다.
그 중에서 배치 사이즈가 16, 32일때 변동성이 줄어드는 결과를
볼 수 있었고 배치 16, 32로 작업을 결정했습니다.

배치 사이즈 16, 32에서
Learning rate를 0.0001과 0.00005로 조정했을때
큰 차이 없이 비슷한 양상을 확인할 수 있었고

배치 사이즈 16, 32 둘다 0.0001에서 약간 더 나은 결과를 보여줬고
마지막으로 둘을 비교한 후
배치 사이즈 16에 Learning rate 0.0001로 작업을 결정했습니다.

이후 1000번까지 실행해도 의미있는 변화는 없어서
최종적으로 에포크 57에서 끊기로 결정했습니다.

여기부터는 vgg 모델 히스토리를 설명드리겠습니다.
Learning rate 0.001에 배치 사이즈를 조정한 비교 그래프 입니다.
학습이 경사가 가파르고 빠르게 과적합으로 가는것이 보이고
그에 맞춰 테스트 loss값은 오르면서 정확도는 떨어지는
결과를 볼 수 있었습니다.

Learning rate를 0.0001로 낮춰서 비교해 봤을때
16회차에서 그래프에서 변화를 확인했습니다.

Learning rate를 완전히 0.00001까지 낮춰서 비교했을 때는
Train의 과적합 문제가 발생하지 않았고
11회차 그래프가 좋은 결과를 보여주었습니다.

실행결과를 정리하자면 
vgg 모델의 학습이 빨라서 과적합 문제가 발생했고
이로인해 Test의 정확도는 하락 Loss값이 상승하는 원인을 볼 수 있었고
이를 안정화 하게 위해서는 Learning rate 값을 매우 작게 하고
그에 맞는 배치사이즈를 맞춰야 한다는 결론을 얻을 수 있었습니다.

앞에서 괜찮은 결과를 보여주었던 11, 16회차 그래프를 비교했을 때
16회차의 loss값이 상승하기 전에 가장 높은 정확도를 확인할 수 있었습니다.
따라서 16회차 모델의 에포크 21로 최종 결정했습니다.

마지막으로 resnet과 vgg의 혼동행렬을 비교했을 때
각각 정확도 68%, 74%가 나왔고
양쪽다 정밀도가 약 3% 6%
재현율 54% 94%가 나왔습니다.
최종적으로는 vgg모델을 선택했습니다.
모델의 한계점으로는 양성은 94% 잘 걸러내지만
데이터 부족의 문제로 음성도 양성으로 오분류하는 해서
이를 차후 개선해야 한다는 점입니다.

===================================================
챗봇 파트 입니다.

시연 영상 먼저 보여드리겠습니다.

챗봇 사용 목적으로는
사용자에게 주변의 선별진료소를 알려주고
접근성
시간이나 공간에 제약이 없다
전문적이고 일괄적인 정보 전달이 가능하다
이를 바탕으로 피드백과 대처 방안을 수립할 수 있다가 있습니다.

챗봇 구조도입니다.
사용자가 문구를 입력하면
다이얼로그 플로우에서 문장을 파악한 뒤
웹훅을 이용해 플라스크 서버와 통신하여 답변을 해줍니다.

지역 병원 정보를 크롤링한 데이터 원본을
Q/A 형태로 바꿔서 데이터 전처리를 실시했습니다.

챗봇에서 사용한 임베딩을 간략하게 설명드리면
컴퓨터가 글자의 유사도를 찾을 수 있도록 변환하는 과정입니다.

챗봇을 쓸 때마다 임베딩을 하면 통신속도가 느려지기 때문에
임베딩한 csv파일을 따로 저장해서 쓰는 방법으로 했고
사용자가 입력 했을 때 cos 유사도를 비교해서 가장 유사한 답변을 돌려줍니다.

엔티티 구성에서는 
자치구 25개
행정동 426개
법정동 467개를 사용했고
호영님이 수작업으로 검토하면서 입력해 주셨습니다.

챗봇에서 사용자와의 대화 흐름을 보다 원할히 하기 위해서
버튼 형식으로 대화를 유도할 수 있도록 했습니다.

챗봇과 플라스크 서버간 연결을 위해서 풀필먼트의 웹훅을 활성화 한 후
URL을 입력해 서버로 배포 했습니다.

링크 기능을 포함한 메시지카드로 Q&A와 지도 페이지로 이동할 수 있게
구성했습니다.

 ===================================================
플라스크 파트입니다.

플라스크 구조도로 전체적인 프로세스를 설명드리겠습니다.
사용자가 기침 소리를 녹음하면
멜스펙트로그램으로 변환 후 AI 모델에 입력합니다.
코로나 양성 음성 여부를 분류하고
사용자에게 결과를 출력해 줍니다.
사용자가 챗봇으로 위치를 입력하면
서버로 부터 주소를 전송하고
그에 따른 결과를 받습니다.
마지막으로 코로나 진료 병원을 답변으로 돌려줍니다.
데이터 베이스에는 회원 정보와 
데이터 수집을 위해 녹음한 파일을 저장해둔 경로 등을 저장했습니다.

화면 구성으로는
홈 화면
로그인 화면
회원가입 화면이고
데이터 베이스에서는 비밀번호를 암호화 해서 관리합니다.

AI 검증 화면에서는 기침 소리 녹음후 결과 보러 가기로
양성/ 음성 페이지를 보여줍니다.

카카오맵을 사용해 지도 화면을 구성했고
추가적으로 확진시 조치 안내 페이지와
코로나 Q&A 페이지를 넣었습니다.
예방접종 현황판은 질병관리청을 벤치마킹해봤습니다.

예방접종 현황판에서 사용한 RPA 영상입니다.

RPA 코드와 이를 사용해 질병관리청에서 추출한 데이터입니다.

자동화를 위해 오케스트레이터와 스케줄러를 사용했고
각각 평일 오전 9시 35분과 40에 실행하도록 설정해 두었습니다.

목소리 유사도에서는 비교할 전후 목소리를 녹음한 후 멜스펙트로그램으로 변환합니다
librosa 패키지에 있는 mfcc를 사용해 목소리의 특징 값을 추출해 벡터 값을 구하고
이를 가지고 cos 유사도를 계산해 목소리가 얼마나 변했는지 결과를 출력합니다.

목소리 유사도 녹음 화면과 결과 화면입니다.

코로나 예측 그래프에서는 프로펫을 사용했고
사용 목적으로는
확진 동향 예측과 이를 토대로 정책 및 계획을 미리 수립할 수 있다는 점이 있습니다.

전처리한 데이터로 시계열 예측 패키지인 프로펫을 사용해 일주일 동향을 예측해 보았습니다.
Changepoint_prior_scale 는 값이 커질 수록 모델을 유연하게 만드는 속성이고
Changepoint_range는 데이터 앞쪽 몇 퍼센트 부분안에서 변화점을 만들 것인지 설정하는 함수입니다.

까만색 점들은 실제 확진자 수 데이터이며, 신규 확진자 수는 점점 늘어날 것으로 예측하는 그래프를 그리고 있습니다.

프로펫으로 예측한 그래프를 chat js를 사용해서 시각화 한 후
홈 화면에 붙였습니다.

===================================================
마무리 파트입니다.

보완할 점 읽고

느낀 점 읽고

출처

감사합니다

질문










