{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5916b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "미션1\n",
    "여러명이 들어 있는 이미지 10장\n",
    "각 이미지별 얼굴을 ditect 하고\n",
    "이미지별 폴더 만들고, 그 폴더 안에 각 얼굴을 저장하시오\n",
    "결과: 열개의 폴더가 만들어지고, 각 폴더 안에 ditect된 얼굴이미지가 있어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eefdab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재작업폴더의 faceimage폴더안에 사각영역이 파일로 저장되었음\n",
      "현재작업폴더의 faceimage폴더안에 사각영역이 파일로 저장되었음\n",
      "현재작업폴더의 faceimage폴더안에 사각영역이 파일로 저장되었음\n",
      "현재작업폴더의 faceimage폴더안에 사각영역이 파일로 저장되었음\n",
      "현재작업폴더의 faceimage폴더안에 사각영역이 파일로 저장되었음\n",
      "현재작업폴더의 faceimage폴더안에 사각영역이 파일로 저장되었음\n",
      "현재작업폴더의 faceimage폴더안에 사각영역이 파일로 저장되었음\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_alt.xml')\n",
    "\n",
    "for i in range(1,8,1):\n",
    "    img_name = str(i)\n",
    "\n",
    "    # 얼굴 인식\n",
    "    img = cv2.imread(f'./GroupPhoto/{img_name}.jpg')\n",
    "#     print(f'./{img_name}.jpg')\n",
    "#     print(img.shape)\n",
    "    faces = face_cascade.detectMultiScale(img, 1.1, 3)\n",
    "#     print('faces', faces)\n",
    "\n",
    "    # 얼굴 인식 확인\n",
    "    for x,y,w,h in faces:\n",
    "        x1 = x - 20\n",
    "        y1 = y - 20\n",
    "        x2 = x + w + 20\n",
    "        y2 = y + h + 20\n",
    "        if x1 < 0:\n",
    "            x1 = 0\n",
    "        elif x2 > img.shape[1]:\n",
    "            x2 = img.shape[1]\n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "        elif y2 > img.shape[0]:\n",
    "            y2 = img.shape[0]\n",
    "            \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)   \n",
    "    cv2.imshow(\"test1\", img)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # 얼굴이미지만 별도로 저장하고자 한다면\n",
    "    img = cv2.imread(f'./GroupPhoto/{img_name}.jpg')\n",
    "    cnt=0\n",
    "\n",
    "    for x,y,w,h in faces:\n",
    "        x1 = x - 20\n",
    "        y1 = y - 20\n",
    "        x2 = x + w + 20\n",
    "        y2 = y + h + 20\n",
    "        if x1 < 0:\n",
    "            x1 = 0\n",
    "        elif x2 > img.shape[1]:\n",
    "            x2 = img.shape[1]\n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "        elif y2 > img.shape[0]:\n",
    "            y2 = img.shape[0]\n",
    "            \n",
    "        cnt = cnt+1\n",
    "        사각영역array = img[y1:y2, x1:x2]\n",
    "        path = f'./{img_name}/'\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        fileName = f'./{img_name}/' + str(cnt) + 'face.jpg'\n",
    "        cv2.imwrite(fileName,사각영역array)\n",
    "\n",
    "    print('현재작업폴더의 faceimage폴더안에 사각영역이 파일로 저장되었음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43be5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "img = cv2.imread('./image9.jpg')\n",
    "faces = face_cascade.detectMultiScale(img, 1.1, 4)\n",
    "\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img, (x-20, y-20), (x + w+20, y + h+20), (255, 0, 0), 2)   \n",
    "cv2.imshow(\"test1\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3be122",
   "metadata": {},
   "outputs": [],
   "source": [
    "미션2\n",
    "사진 또는 동영상파일, 카메라 등 얼굴 ditect해서\n",
    "ditect 한 곳 살짝 위로 텍스트 입력 ('face')\n",
    "이미지 처리 (블러, 모자이크처리 등)\n",
    "캐릭터 이미지와 합성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09defdc4",
   "metadata": {},
   "source": [
    "### 얼굴 인식 및 텍스트 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17d6dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture('./iloom_interview.mp4') #장치ID가 아닌 동영상 파일명만 바꾸면 됨\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# 카메라 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read() #카메라로부터 정상적으로 프레임을 받아 오면 ret-> True, frame-> 해당 프레임저장\n",
    "\n",
    "\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.1, 3)\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(frame, (x-20, y-20), (x + w+20, y + h+20), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, \"face\" , (x,y-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) == 27:  # 일정시간 (예,10ms) 후 다음 프레임 읽음, 만약 ESC(27)키를 누르면 break\n",
    "        break\n",
    "cap.release() # 사용한 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22195217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0) #장치ID가 아닌 동영상 파일명만 바꾸면 됨\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_alt.xml')\n",
    "\n",
    "\n",
    "# 카메라 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read() #카메라로부터 정상적으로 프레임을 받아 오면 ret-> True, frame-> 해당 프레임저장\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.1, 3)\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(frame, (x-20, y-20), (x + w+20, y + h+20), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, \"face\" , (x,y-30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,0,0), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) == 27:  # 일정시간 (예,10ms) 후 다음 프레임 읽음, 만약 ESC(27)키를 누르면 break\n",
    "        break\n",
    "cap.release() # 사용한 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d878a770",
   "metadata": {},
   "source": [
    "### 얼굴 인식 및 블러처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64925f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture('./iloom_interview.mp4') #장치ID가 아닌 동영상 파일명만 바꾸면 됨\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# 카메라 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read() #카메라로부터 정상적으로 프레임을 받아 오면 ret-> True, frame-> 해당 프레임저장\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.1, 3)\n",
    "    for x,y,w,h in faces:        \n",
    "        cv2.rectangle(frame, (x-20, y-20), (x + w+20, y + h+20), (255, 0, 0), 2)\n",
    "        frame[y-20:y+h+20, x-20:x+w+20] = cv2.blur(frame[y-20:y+h+20, x-20:x+w+20], (30,30), anchor=(-1,-1), borderType=cv2.BORDER_DEFAULT)\n",
    "\n",
    "        tmp=cv2.resize(frame[y-20:y+h+20, x-20:x+w+20], (20, 20))\n",
    "        w1=abs(w+40)\n",
    "        h1=abs(h+40)\n",
    "        frame[y-20:y+h+20, x-20:x+w+20]=cv2.resize(tmp,(w1,h1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) == 27:  # 일정시간 (예,10ms) 후 다음 프레임 읽음, 만약 ESC(27)키를 누르면 break\n",
    "        break\n",
    "cap.release() # 사용한 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "702981f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0) #장치ID가 아닌 동영상 파일명만 바꾸면 됨\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# 카메라 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read() #카메라로부터 정상적으로 프레임을 받아 오면 ret-> True, frame-> 해당 프레임저장\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.1, 3)\n",
    "    for x,y,w,h in faces:\n",
    "        \n",
    "        cv2.rectangle(frame, (x-20, y-20), (x + w+20, y + h+20), (255, 0, 0), 2)\n",
    "        frame[y-20:y+h+20, x-20:x+w+20] = cv2.blur(frame[y-20:y+h+20, x-20:x+w+20], (30,30), anchor=(-1,-1), borderType=cv2.BORDER_DEFAULT)\n",
    "\n",
    "        tmp=cv2.resize(frame[y-20:y+h+20, x-20:x+w+20], (20, 20))\n",
    "        w1=abs(w+40)\n",
    "        h1=abs(h+40)\n",
    "        frame[y-20:y+h+20, x-20:x+w+20]=cv2.resize(tmp,(w1,h1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) == 27:  # 일정시간 (예,10ms) 후 다음 프레임 읽음, 만약 ESC(27)키를 누르면 break\n",
    "        break\n",
    "cap.release() # 사용한 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b3dafc",
   "metadata": {},
   "source": [
    "### 얼굴 인식 및 마스크 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1433bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture('./iloom_interview.mp4') #장치ID가 아닌 동영상 파일명만 바꾸면 됨\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "image_cat = cv2.imread('./cat_mask.png',cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "# 카메라 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read() #카메라로부터 정상적으로 프레임을 받아 오면 ret-> True, frame-> 해당 프레임저장\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.1, 3)\n",
    "    for x,y,w,h in faces:\n",
    "        # 나비 사각형 크기 맞춰서 바꾸기\n",
    "        tmp=cv2.resize(image_cat,(w+40,h+40))\n",
    "        # 마스크 0~255를 0~1로 비율 맞추기\n",
    "        mask_img=tmp[:,:,3]/255\n",
    "        \n",
    "        for c in range(3):\n",
    "            img_sum1 = tmp[:,:,c]*mask_img\n",
    "            img_sum2 = frame[y-20:y+h+20,x-20:x+w+20,c]*(1-mask_img)\n",
    "            frame[y-20:y+h+20,x-20:x+w+20,c]=(img_sum1+img_sum2).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) == 27:  # 일정시간 (예,10ms) 후 다음 프레임 읽음, 만약 ESC(27)키를 누르면 break\n",
    "        break\n",
    "cap.release() # 사용한 자원 해제\n",
    "cv2.destroyAllWindows()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "018fa337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0) #장치ID가 아닌 동영상 파일명만 바꾸면 됨\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "image_cat = cv2.imread('./cat_mask.png',cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "# 카메라 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read() #카메라로부터 정상적으로 프레임을 받아 오면 ret-> True, frame-> 해당 프레임저장\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.1, 3, minSize=(100,100))\n",
    "    for x,y,w,h in faces:\n",
    "        # 나비 사각형 크기 맞춰서 바꾸기\n",
    "        tmp=cv2.resize(image_cat,(w+40,h+40))\n",
    "        # 마스크 0~255를 0~1로 비율 맞추기\n",
    "        mask_img=tmp[:,:,3]/255\n",
    "        \n",
    "        for c in range(3):\n",
    "            img_sum1 = tmp[:,:,c]*mask_img\n",
    "            img_sum2 = frame[y-20:y+h+20,x-20:x+w+20,c]*(1-mask_img)\n",
    "            frame[y-20:y+h+20,x-20:x+w+20,c]=(img_sum1+img_sum2).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) == 27:  # 일정시간 (예,10ms) 후 다음 프레임 읽음, 만약 ESC(27)키를 누르면 break\n",
    "        break\n",
    "cap.release() # 사용한 자원 해제\n",
    "cv2.destroyAllWindows()       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac28b03",
   "metadata": {},
   "source": [
    "### 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7707fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0) #장치ID가 아닌 동영상 파일명만 바꾸면 됨\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "image_cat = cv2.imread('./cat_mask.png',cv2.IMREAD_UNCHANGED)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX') #코덱 설정\n",
    "out = cv2.VideoWriter('output(1).avi', fourcc, 25.0, (640,480)) #영상을 저장할 객체 생성\n",
    "\n",
    "\n",
    "# 카메라 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read() #카메라로부터 정상적으로 프레임을 받아 오면 ret-> True, frame-> 해당 프레임저장\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.1, 3, minSize=(100,100))\n",
    "    for x,y,w,h in faces:\n",
    "        # 나비 사각형 크기 맞춰서 바꾸기\n",
    "        tmp=cv2.resize(image_cat,(w+40,h+40))\n",
    "        # 마스크 0~255를 0~1로 비율 맞추기\n",
    "        mask_img=tmp[:,:,3]/255\n",
    "        \n",
    "        for c in range(3):\n",
    "            img_sum1 = tmp[:,:,c]*mask_img\n",
    "            img_sum2 = frame[y-20:y+h+20,x-20:x+w+20,c]*(1-mask_img)\n",
    "            frame[y-20:y+h+20,x-20:x+w+20,c]=(img_sum1+img_sum2).astype(np.uint8)\n",
    "\n",
    "    out.write(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) == 27:  # 일정시간 (예,10ms) 후 다음 프레임 읽음, 만약 ESC(27)키를 누르면 break\n",
    "        break\n",
    "cap.release() # 사용한 자원 해제\n",
    "cv2.destroyAllWindows()       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eca651",
   "metadata": {},
   "source": [
    "### 2명 이상 (형근님 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81c94656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "# 객체 생성 및 학습 데이터 불러오기\n",
    "#얼굴 검출\n",
    "face_classifier = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "#눈 검출\n",
    "eye_classifier = cv2.CascadeClassifier('.\\haarcascade_eye.xml')\n",
    "\n",
    "while True:\n",
    "    #비디오의 한 프레임씩 읽는다.\n",
    "    #제대로 읽으면 ret는 True, frame에는 읽은 프레임이 나온다.\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    # 멀티 스케일 객체 검출 함수\n",
    "    faces = face_classifier.detectMultiScale(frame, minSize=(100, 100), maxSize=(400, 400))\n",
    "\n",
    "    # 영상 받아오기\n",
    "    for (x, y, w, h) in faces:\n",
    "        # 얼굴 빨간색 사각형 그리기\n",
    "        cv2.rectangle(frame, (x, y, w, h), (255, 0, 255), 2)\n",
    "        tmp = cv2.resize(frame[y:y+h,x:x+w], (10, 10))\n",
    "        frame[y:y+h,x:x+w] = cv2.resize(tmp,(w,h))\n",
    "\n",
    "        #눈 검출\n",
    "        face_half = frame[y:y + h // 2, x:x + w] #위 화면에서만 (빨리 찾기 위함)\n",
    "        eyes = eye_classifier.detectMultiScale(face_half)\n",
    "\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            # 눈 파란색 사각형 그리기\n",
    "            cv2.rectangle(face_half, (ex, ey, ew, eh), (255, 0, 0), 2) \n",
    "\n",
    "    cv2.imshow('IT42', frame)\n",
    "\n",
    "    if cv2.waitKey(10) == 27: #esc 키를 누르면 종료\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ff71a3",
   "metadata": {},
   "source": [
    "### 얼굴 마스킹 (호영님 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f69ec2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread() \u001b[38;5;66;03m#카메라로부터 정상적으로 프레임을 받아 오면 ret-> True, frame-> 해당 프레임저장\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     faces \u001b[38;5;241m=\u001b[39m face_cascade\u001b[38;5;241m.\u001b[39mdetectMultiScale(\u001b[43mgray\u001b[49m,\u001b[38;5;241m1.3\u001b[39m,\u001b[38;5;241m5\u001b[39m) \n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(faces):\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (x,y,w,h) \u001b[38;5;129;01min\u001b[39;00m faces:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gray' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 카메라 열기\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "cap = cv2.VideoCapture(0) #장치ID가 아닌 동영상 파일명만 바꾸면 됨\n",
    "image2=cv2.imread('./navi.png',cv2.IMREAD_UNCHANGED)\n",
    "# 카메라 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read() #카메라로부터 정상적으로 프레임을 받아 오면 ret-> True, frame-> 해당 프레임저장\n",
    "    faces = face_cascade.detectMultiScale(frame,1.3,5) \n",
    "    if len(faces):\n",
    "        for (x,y,w,h) in faces:\n",
    "            tmp=cv2.resize(image2,(w,h))\n",
    "            mask_img=tmp[:,:,3]/255\n",
    "            #이미지 합치기\n",
    "            for c in range(3):\n",
    "                img_sum1 = (tmp[:,:,c]*mask_img)\n",
    "                img_sum2 = (frame[y:y+h, x:x+w,c]*(1-mask_img))\n",
    "                frame[y:y+h, x:x+w,c]=(img_sum1+img_sum2).astype(np.uint8)\n",
    "\n",
    "        cv2.imshow('result', frame)\n",
    "        \n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27: # Esc 키를 누르면 종료\n",
    "            break\n",
    "cap.release() # 사용한 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5019ce4",
   "metadata": {},
   "source": [
    "### 2명이상, 화면 밖으로 나가는거 에러 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a7b0029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 카메라 열기\n",
    "cap = cv2.VideoCapture(0) #장치ID가 아닌 동영상 파일명만 바꾸면 됨\n",
    "face_cascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# 카메라 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read() #카메라로부터 정상적으로 프레임을 받아 오면 ret-> True, frame-> 해당 프레임저장\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(frame, 1.1, 3)\n",
    "    for x,y,w,h in faces:\n",
    "        x1 = x - 20\n",
    "        y1 = y - 20\n",
    "        x2 = x + w + 20\n",
    "        y2 = y + h + 20\n",
    "        if x1 < 0:\n",
    "            x1 = 0\n",
    "        elif x2 > frame.shape[1]:\n",
    "            x2 = frame.shape[1]\n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "        elif y2 > frame.shape[0]:\n",
    "            y2 = frame.shape[0]\n",
    "        \n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "        frame[y1:y2, x1:x2] = cv2.blur(frame[y1:y2, x1:x2], (30,30), anchor=(-1,-1), borderType=cv2.BORDER_DEFAULT)\n",
    "\n",
    "        tmp=cv2.resize(frame[y1:y2, x1:x2], (20, 20))\n",
    "        w1=abs(x2-x1)\n",
    "        h1=abs(y2-y1)\n",
    "        frame[y1:y2, x1:x2]=cv2.resize(tmp,(w1,h1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(20) == 27:  # 일정시간 (예,10ms) 후 다음 프레임 읽음, 만약 ESC(27)키를 누르면 break\n",
    "        break\n",
    "cap.release() # 사용한 자원 해제\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0432193e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
