{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f3c0946",
   "metadata": {},
   "source": [
    "### mediapipe로 얼굴 인식하기\n",
    "\n",
    "- 참고\" https://mediapipe.dev/\n",
    "\n",
    "> !pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d9f52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring empty camera frame.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 얼굴 찾고, 특징 표시\n",
    "mp_face_detection = mp.solutions.face_detection #얼굴 검출\n",
    "mp_drawing = mp.solutions.drawing_utils # 얼굴 특징 표시\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture('./face_video.mp4')\n",
    "# model_selection=0 -> 2m 내, model_selection=1 -> 5m 내\n",
    "with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "      while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            break\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_detection.process(image)\n",
    "\n",
    "        # Draw the face detection annotations on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.detections:\n",
    "            for detection in results.detections:\n",
    "                #mp_drawing.draw_detection(image, detection)\n",
    "                #######################################################################################################\n",
    "                # detdection 정보 확인\n",
    "                # - 얼굴 경계 상자(relative_bounding_box)\n",
    "                # - 6개의 특징 축출(relative_keypoints): 오른쪽 눈, 왼쪽 눈, 코끝, 입 중심, 오른쪽 귀, 왼쪽 귀\n",
    "                # print(detection) # 전체 detection 확인\n",
    "                # print(detection.location_data.relative_bounding_box) # 얼굴 경계 박스 확인\n",
    "                # print(detection.location_data.relative_keypoints) # (왼쪽 눈, 코끝, 입 중심, 오른쪽 귀, 왼쪽 귀) 리스트로 반환\n",
    "                # print(detection.location_data.relative_keypoints)[0] # 왼쪽 눈 반환\n",
    "                #\n",
    "                # [참고]\n",
    "                # 경계 상자는 xminand width(둘 다 [0.0, 1.0]이미지 너비로 정규화됨) 및 yminand height(둘 다 [0.0, 1.0]이미지 높이로 정규화됨) \n",
    "                # 각 키 포인트는 이미지 너비와 높이로 각각 정규화되는 x및 로 구성됩니다.y[0.0, 1.0]\n",
    "                #######################################################################################################\n",
    "                \n",
    "                #특정 위치 가져오기 (오른쪽 눈, 왼쪽 눈, 코끝 )\n",
    "                keypoints=detection.location_data.relative_keypoints\n",
    "                right_eye= keypoints[0] #오른쪽 눈\n",
    "                left_eye=keypoints[1] #왼쪽 눈\n",
    "                \n",
    "                # 이미지 전체 크기를 바탕으로  실제 좌표로 반환함\n",
    "                h, w, _=image.shape \n",
    "                right_eye=(int(right_eye.x*w), int(right_eye.y*h)) # 이미지 내의 실제 좌표로 변환\n",
    "                left_eye=(int(left_eye.x*w),int(left_eye.y*h))\n",
    "                \n",
    "                # 양 눈에 동그라미 그리기\n",
    "                cv2.circle(image,right_eye,20,(255,0,0),2,cv2.LINE_AA) #파란색\n",
    "                cv2.circle(image,left_eye,20,(0,0,255),2,cv2.LINE_AA) #빨강색\n",
    "                \n",
    "                \n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d615dc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_id: 0\n",
       "score: 0.8782748579978943\n",
       "location_data {\n",
       "  format: RELATIVE_BOUNDING_BOX\n",
       "  relative_bounding_box {\n",
       "    xmin: 0.30861350893974304\n",
       "    ymin: 0.3233301639556885\n",
       "    width: 0.16154515743255615\n",
       "    height: 0.3058851361274719\n",
       "  }\n",
       "  relative_keypoints {\n",
       "    x: 0.32726427912712097\n",
       "    y: 0.38738030195236206\n",
       "  }\n",
       "  relative_keypoints {\n",
       "    x: 0.3703916072845459\n",
       "    y: 0.3909175395965576\n",
       "  }\n",
       "  relative_keypoints {\n",
       "    x: 0.3093099594116211\n",
       "    y: 0.438238263130188\n",
       "  }\n",
       "  relative_keypoints {\n",
       "    x: 0.32081541419029236\n",
       "    y: 0.5205081701278687\n",
       "  }\n",
       "  relative_keypoints {\n",
       "    x: 0.35567620396614075\n",
       "    y: 0.4430972933769226\n",
       "  }\n",
       "  relative_keypoints {\n",
       "    x: 0.46987876296043396\n",
       "    y: 0.46285098791122437\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf2bb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "format: RELATIVE_BOUNDING_BOX\n",
       "relative_bounding_box {\n",
       "  xmin: 0.30861350893974304\n",
       "  ymin: 0.3233301639556885\n",
       "  width: 0.16154515743255615\n",
       "  height: 0.3058851361274719\n",
       "}\n",
       "relative_keypoints {\n",
       "  x: 0.32726427912712097\n",
       "  y: 0.38738030195236206\n",
       "}\n",
       "relative_keypoints {\n",
       "  x: 0.3703916072845459\n",
       "  y: 0.3909175395965576\n",
       "}\n",
       "relative_keypoints {\n",
       "  x: 0.3093099594116211\n",
       "  y: 0.438238263130188\n",
       "}\n",
       "relative_keypoints {\n",
       "  x: 0.32081541419029236\n",
       "  y: 0.5205081701278687\n",
       "}\n",
       "relative_keypoints {\n",
       "  x: 0.35567620396614075\n",
       "  y: 0.4430972933769226\n",
       "}\n",
       "relative_keypoints {\n",
       "  x: 0.46987876296043396\n",
       "  y: 0.46285098791122437\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection.location_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7caa3451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[x: 0.32726427912712097\n",
       "y: 0.38738030195236206\n",
       ", x: 0.3703916072845459\n",
       "y: 0.3909175395965576\n",
       ", x: 0.3093099594116211\n",
       "y: 0.438238263130188\n",
       ", x: 0.32081541419029236\n",
       "y: 0.5205081701278687\n",
       ", x: 0.35567620396614075\n",
       "y: 0.4430972933769226\n",
       ", x: 0.46987876296043396\n",
       "y: 0.46285098791122437\n",
       "]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection.location_data.relative_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f3ecf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.32726427912712097\n",
       "y: 0.38738030195236206"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection.location_data.relative_keypoints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122c8796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.3703916072845459\n",
       "y: 0.3909175395965576"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection.location_data.relative_keypoints[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd2338",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
